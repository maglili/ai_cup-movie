{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fb786d26",
   "metadata": {},
   "source": [
    "# Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "34dc7a9a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/lichang/.virtualenvs/py38/lib/python3.8/site-packages/pandas/compat/__init__.py:97: UserWarning: Could not import the lzma module. Your installed Python is incomplete. Attempting to use lzma compression will result in a RuntimeError.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 1 GPU(s) available.\n",
      "We will use the GPU: GeForce RTX 2080 Ti\n",
      "==========\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# load basic library\n",
    "import random\n",
    "import numpy as np\n",
    "import pickle\n",
    "from tqdm import tqdm\n",
    "\n",
    "# load torch library\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader, TensorDataset\n",
    "from transformers import (\n",
    "    AutoTokenizer,\n",
    "    AutoModelForSequenceClassification,\n",
    "    AdamW,\n",
    "    get_linear_schedule_with_warmup,\n",
    ")\n",
    "\n",
    "# custum module\n",
    "from tools import *\n",
    "\n",
    "# keep reandom seed\n",
    "seed_val = 0\n",
    "random.seed(seed_val)\n",
    "np.random.seed(seed_val)\n",
    "torch.manual_seed(seed_val)\n",
    "\n",
    "# check gpu\n",
    "device = get_device()\n",
    "\n",
    "\n",
    "# load data\n",
    "with open(\"./data/pkl/X_train_list.pkl\", \"rb\") as f:\n",
    "    X_train_list = pickle.load(f)\n",
    "with open(\"./data/pkl/X_valid_list.pkl\", \"rb\") as f:\n",
    "    X_valid_list = pickle.load(f)\n",
    "with open(\"./data/pkl/y_train_list.pkl\", \"rb\") as f:\n",
    "    y_train_list = pickle.load(f)\n",
    "with open(\"./data/pkl/y_valid_list.pkl\", \"rb\") as f:\n",
    "    y_valid_list = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "be37142f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epochs: 10\n",
      "batch_size: 8\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model_name = \"bert-base-cased\"\n",
    "\n",
    "# hypterparameter\n",
    "epochs = 10\n",
    "batch_size = 8\n",
    "print(\"epochs:\", epochs)\n",
    "print(\"batch_size:\", batch_size)\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9d244213",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cwd /home/lichang/projects/ai_cup-movie\n",
      "metric_path: /home/lichang/projects/ai_cup-movie/result/bert-base-cased_bs_8_epo10/metrics\n",
      "model_path: /home/lichang/projects/ai_cup-movie/result/bert-base-cased_bs_8_epo10/model\n",
      "history_path: /home/lichang/projects/ai_cup-movie/result/bert-base-cased_bs_8_epo10/history\n",
      "fig_path: /home/lichang/projects/ai_cup-movie/result/bert-base-cased_bs_8_epo10/figures\n"
     ]
    }
   ],
   "source": [
    "# setting path\n",
    "metric_path, model_path, history_path, fig_path = setting_path(\n",
    "    model_name, batch_size, epochs\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4db1d02c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tokenizing for bert input\n",
      "tokenizing for bert input\n"
     ]
    }
   ],
   "source": [
    "# tokenize\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name, do_lower_case=False)\n",
    "\n",
    "(\n",
    "    input_ids_train_dict,\n",
    "    attention_masks_train_dict,\n",
    "    labels_train_dict,\n",
    ") = tokenizing_for_bert(\n",
    "    X_train_list, y_train_list, tokenizer\n",
    ")  # max_len = 400\n",
    "\n",
    "input_ids_cv_dict, attention_masks_cv_dict, labels_cv_dict = tokenizing_for_bert(\n",
    "    X_valid_list, y_valid_list, tokenizer, train=False\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af7a7c68",
   "metadata": {},
   "source": [
    "check average token length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fd884709",
   "metadata": {},
   "outputs": [
    {
     "ename": "AssertionError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-29403cf677e6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32massert\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "assert 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "25ebfade",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([23472, 400])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# all_data = torch.cat((input_ids_train_dict[\"tr_1\"], input_ids_cv_dict[\"va_1\"]), 0)\n",
    "# all_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2af8c178",
   "metadata": {},
   "outputs": [],
   "source": [
    "# token_length = []\n",
    "# for i in all_data:\n",
    "#     token_length.append(sum(i!=0).item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "986b3026",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "215.33452624403546\n",
      "400\n",
      "4\n",
      "127.15932762513401\n"
     ]
    }
   ],
   "source": [
    "# print(np.mean(token_length))\n",
    "# print(np.max(token_length))\n",
    "# print(np.min(token_length))\n",
    "# print(np.std(token_length))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "0d9328e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "231.8667348329925\n",
      "512\n",
      "4\n",
      "153.99549015975495\n"
     ]
    }
   ],
   "source": [
    "# print(np.mean(token_length))\n",
    "# print(np.max(token_length))\n",
    "# print(np.min(token_length))\n",
    "# print(np.std(token_length))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f0b5d13",
   "metadata": {},
   "source": [
    "5-fold dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "379d7f9f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'torch.utils.data.dataset.TensorDataset'>\n"
     ]
    }
   ],
   "source": [
    "# Prepare torch dataset\n",
    "tr_set = []\n",
    "va_set = []\n",
    "for idx in range(len(input_ids_train_dict)):\n",
    "    tr_set.append(\n",
    "        TensorDataset(\n",
    "            input_ids_train_dict[\"tr_\" + str(idx)],\n",
    "            attention_masks_train_dict[\"tr_\" + str(idx)],\n",
    "            labels_train_dict[\"tr_\" + str(idx)],\n",
    "        )\n",
    "    )\n",
    "    va_set.append(\n",
    "        TensorDataset(\n",
    "            input_ids_cv_dict[\"va_\" + str(idx)],\n",
    "            attention_masks_cv_dict[\"va_\" + str(idx)],\n",
    "            labels_cv_dict[\"va_\" + str(idx)],\n",
    "        )\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f7a9f4ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/5 [00:00<?, ?it/s]Some weights of the model checkpoint at bert-base-cased were not used when initializing BertForSequenceClassification: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias']\n",
      "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-cased and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[Fold]: 0\n",
      "Num of train samples: 18777\n",
      "Num of valid samples: 4695\n",
      "\n",
      "training loss: 0.46\n",
      "training acc: 0.79\n",
      "-------------------------\n",
      "train loss: 0.27\n",
      "train acc: 0.91\n",
      "-------------------------\n",
      "valid loss: 0.30\n",
      "valid acc: 0.90\n",
      "-------------------------\n",
      "Validation loss decreased (inf --> 176.791484).  Saving model ...\n",
      "=========================\n",
      "training loss: 0.37\n",
      "training acc: 0.88\n",
      "-------------------------\n",
      "train loss: 0.23\n",
      "train acc: 0.93\n",
      "-------------------------\n",
      "valid loss: 0.32\n",
      "valid acc: 0.91\n",
      "-------------------------\n",
      "EarlyStopping counter: 1 out of 3\n",
      "=========================\n",
      "training loss: 0.34\n",
      "training acc: 0.90\n",
      "-------------------------\n",
      "train loss: 0.19\n",
      "train acc: 0.94\n",
      "-------------------------\n",
      "valid loss: 0.32\n",
      "valid acc: 0.90\n",
      "-------------------------\n",
      "EarlyStopping counter: 2 out of 3\n",
      "=========================\n",
      "training loss: 0.30\n",
      "training acc: 0.92\n",
      "-------------------------\n",
      "train loss: 0.22\n",
      "train acc: 0.95\n",
      "-------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/5 [1:05:05<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "valid loss: 0.48\n",
      "valid acc: 0.91\n",
      "-------------------------\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      "*************************\n",
      "*************************\n",
      "*************************\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# training\n",
    "training_hist = []\n",
    "\n",
    "for fold in tqdm(range(len(tr_set))):\n",
    "\n",
    "    model = AutoModelForSequenceClassification.from_pretrained(\n",
    "        model_name,\n",
    "        num_labels=2,\n",
    "        output_attentions=False,\n",
    "        output_hidden_states=False,\n",
    "        hidden_dropout_prob=0.35,\n",
    "        attention_probs_dropout_prob=0.25,\n",
    "    )\n",
    "    model.to(device)\n",
    "\n",
    "    # This code is taken from:\n",
    "    # https://github.com/huggingface/transformers/blob/5bfcd0485ece086ebcbed2d008813037968a9e58/examples/run_glue.py#L102\n",
    "\n",
    "    # Don't apply weight decay to any parameters whose names include these tokens.\n",
    "    # (Here, the BERT doesn't have `gamma` or `beta` parameters, only `bias` terms)\n",
    "    no_decay = [\"bias\", \"LayerNorm.weight\"]\n",
    "\n",
    "    # Separate the `weight` parameters from the `bias` parameters.\n",
    "    # - For the `weight` parameters, this specifies a 'weight_decay_rate' of 0.01.\n",
    "    # - For the `bias` parameters, the 'weight_decay_rate' is 0.0.\n",
    "    optimizer_grouped_parameters = [\n",
    "        # Filter for all parameters which *don't* include 'bias', 'gamma', 'beta'.\n",
    "        {\n",
    "            \"params\": [\n",
    "                p\n",
    "                for n, p in model.named_parameters()\n",
    "                if not any(nd in n for nd in no_decay)\n",
    "            ],\n",
    "            \"weight_decay_rate\": 0.1,\n",
    "        },\n",
    "        # Filter for parameters which *do* include those.\n",
    "        {\n",
    "            \"params\": [\n",
    "                p\n",
    "                for n, p in model.named_parameters()\n",
    "                if any(nd in n for nd in no_decay)\n",
    "            ],\n",
    "            \"weight_decay_rate\": 0.0,\n",
    "        },\n",
    "    ]\n",
    "\n",
    "    # Note - `optimizer_grouped_parameters` only includes the parameter values, not\n",
    "    # the names.\n",
    "\n",
    "    N_train = len(tr_set[fold])\n",
    "    N_test = len(va_set[fold])\n",
    "    print(\"\\n[Fold]:\", fold)\n",
    "    print(\"Num of train samples:\", N_train)\n",
    "    print(\"Num of valid samples:\", N_test)\n",
    "    print()\n",
    "\n",
    "    optimizer = AdamW(\n",
    "        optimizer_grouped_parameters,\n",
    "        lr=4e-5,  # args.learning_rate - default is 5e-5, our notebook had 2e-5\n",
    "    )\n",
    "\n",
    "    train_dataloader = DataLoader(tr_set[fold], shuffle=True, batch_size=batch_size)\n",
    "\n",
    "    validation_dataloader = DataLoader(\n",
    "        va_set[fold], shuffle=False, batch_size=batch_size\n",
    "    )\n",
    "\n",
    "    # Total number of training steps is [number of batches] x [number of epochs].\n",
    "    # (Note that this is not the same as the number of training samples).\n",
    "    total_steps = len(train_dataloader) * epochs\n",
    "\n",
    "    scheduler = get_linear_schedule_with_warmup(\n",
    "        optimizer, num_warmup_steps=total_steps * 0.1, num_training_steps=total_steps\n",
    "    )\n",
    "\n",
    "    history = train_model(\n",
    "        model=model,\n",
    "        train_loader=train_dataloader,\n",
    "        valid_loader=validation_dataloader,\n",
    "        optimizer=optimizer,\n",
    "        N_train=N_train,\n",
    "        N_test=N_test,\n",
    "        device=device,\n",
    "        scheduler=scheduler,\n",
    "        path=model_path,\n",
    "        epochs=epochs,\n",
    "        patience=3,\n",
    "    )\n",
    "\n",
    "    training_hist.append(history)\n",
    "    print(\"*\" * 25)\n",
    "    print(\"*\" * 25)\n",
    "    print(\"*\" * 25)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "bcb2d219",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save trainin_history\n",
    "with open(os.path.join(history_path, \"hist.pkl\"), \"wb\") as f:\n",
    "    pickle.dump(training_hist, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "345a76d7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/lichang/projects/ai_cup-movie/result/bert-base-cased_bs_8_epo10/metrics'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metric_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "79c30226",
   "metadata": {},
   "outputs": [],
   "source": [
    "def final_metric(history, path, mtype=\"train\"):\n",
    "    \"\"\"\n",
    "    Calculate metric.\n",
    "    \"\"\"\n",
    "    # init\n",
    "    ACC = []\n",
    "    LOSS = []\n",
    "    RECALL = []\n",
    "    SPECIFICITY = []\n",
    "    PRECISION = []\n",
    "    NPV = []\n",
    "    F1 = []\n",
    "    MCC = []\n",
    "    AUC = []\n",
    "    FPR = []\n",
    "    TPR = []\n",
    "\n",
    "    for i in range(len(history)):\n",
    "\n",
    "        (TP, FP, TN, FN) = history[i][mtype + \"_metric\"][-1]\n",
    "        auc = history[i][mtype + \"_auc\"][-1]\n",
    "        fpr = history[i][mtype + \"_fpr\"][-1]\n",
    "        tpr = history[i][mtype + \"_tpr\"][-1]\n",
    "        loss = history[i][mtype + \"_loss\"][-1]\n",
    "\n",
    "        acc = (TP + TN) / (TP + FP + TN + FN)\n",
    "\n",
    "        recall = TP / (TP + FN) if TP != 0 else 0  # 召回率是在所有正樣本當中，能夠預測多少正樣本的比例\n",
    "        specificity = TN / (TN + FP) if TN != 0 else 0  # 特異度是在所有負樣本當中，能夠預測多少負樣本的比例\n",
    "        precision = TP / (TP + FP) if TP != 0 else 0  # 準確率為在所有預測為正樣本中，有多少為正樣本\n",
    "        npv = TN / (TN + FN) if TN != 0 else 0  # npv為在所有預測為負樣本中，有多少為負樣本\n",
    "        f1 = (\n",
    "            (2 * recall * precision) / (recall + precision)\n",
    "            if (recall + precision) != 0\n",
    "            else 0\n",
    "        )  # F1-score則是兩者的調和平均數\n",
    "\n",
    "        mcc = (\n",
    "            (TP * TN - FP * FN)\n",
    "            / np.sqrt(((TP + FP) * (TP + FN) * (TN + FP) * (TN + FN)))\n",
    "            if ((TP + FP) * (TP + FN) * (TN + FP) * (TN + FN)) != 0\n",
    "            else 0\n",
    "        )\n",
    "\n",
    "        ACC.append(acc)\n",
    "        LOSS.append(loss)\n",
    "        RECALL.append(recall)\n",
    "        SPECIFICITY.append(specificity)\n",
    "        PRECISION.append(precision)\n",
    "        NPV.append(npv)\n",
    "        F1.append(f1)\n",
    "        MCC.append(mcc)\n",
    "        AUC.append(auc)\n",
    "        FPR.append(fpr)\n",
    "        TPR.append(tpr)\n",
    "\n",
    "    print(\"\\n[\" + mtype + \" average]\\n\")\n",
    "    print(\"ACC: {:.2}\".format((np.mean(ACC))))\n",
    "    print(\"LOSS: {:.2}\".format(np.mean(LOSS)))\n",
    "    print()\n",
    "    print(\"Recall: {:.2}\".format(np.mean(RECALL)))\n",
    "    print(\"Specificity: {:.2}\".format(np.mean(SPECIFICITY)))\n",
    "    print(\"Precision: {:.2}\".format(np.mean(PRECISION)))\n",
    "    print(\"NPV: {:.2}\".format(np.mean(NPV)))\n",
    "    print()\n",
    "    print(\"F1: {:.2}\".format(np.mean(F1)))\n",
    "    print(\"MCC: {:.2}\".format(np.mean(MCC)))\n",
    "    print(\"AUC: {:.2}\".format(np.mean(AUC)))\n",
    "    print()\n",
    "\n",
    "    # save result\n",
    "    save_metrics(\n",
    "        path,\n",
    "        mtype,\n",
    "        ACC,\n",
    "        LOSS,\n",
    "        RECALL,\n",
    "        SPECIFICITY,\n",
    "        PRECISION,\n",
    "        NPV,\n",
    "        F1,\n",
    "        MCC,\n",
    "        AUC,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "f463ac12",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_metrics(\n",
    "    path,\n",
    "    mtype,\n",
    "    ACC,\n",
    "    LOSS,\n",
    "    RECALL,\n",
    "    SPECIFICITY,\n",
    "    PRECISION,\n",
    "    NPV,\n",
    "    F1,\n",
    "    MCC,\n",
    "    AUC,\n",
    "):\n",
    "    \"\"\"\n",
    "    save metrics as csv files\n",
    "    \"\"\"\n",
    "    filename = mtype + \"_metrics.txt\"\n",
    "    file_path = os.path.join(path, filename)\n",
    "    with open(file_path, \"w\", newline=\"\", encoding=\"utf-8\") as csvfile:\n",
    "        writer = csv.writer(csvfile, delimiter=\"\\t\")\n",
    "        writer.writerow([\"[\" + mtype + \" average]\"])\n",
    "        writer.writerow([\"ACC: {:.2}\".format((np.mean(ACC)))])\n",
    "        writer.writerow([\"LOSS: {:.2}\".format(np.mean(LOSS))])\n",
    "        writer.writerow([\"Recall: {:.2}\".format(np.mean(RECALL))])\n",
    "        writer.writerow([\"Specificity: {:.2}\".format(np.mean(SPECIFICITY))])\n",
    "        writer.writerow([\"Precision: {:.2}\".format(np.mean(PRECISION))])\n",
    "        writer.writerow([\"NPV: {:.2}\".format(np.mean(NPV))])\n",
    "        writer.writerow([\"F1: {:.2}\".format(np.mean(F1))])\n",
    "        writer.writerow([\"MCC: {:.2}\".format(np.mean(MCC))])\n",
    "        writer.writerow([\"AUC: {:.2}\".format(np.mean(AUC))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "18b5f027",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[train average]\n",
      "\n",
      "ACC: 0.95\n",
      "LOSS: 0.22\n",
      "\n",
      "Recall: 0.93\n",
      "Specificity: 0.98\n",
      "Precision: 0.98\n",
      "NPV: 0.93\n",
      "\n",
      "F1: 0.95\n",
      "MCC: 0.91\n",
      "AUC: 0.99\n",
      "\n",
      "\n",
      "[valid average]\n",
      "\n",
      "ACC: 0.91\n",
      "LOSS: 0.48\n",
      "\n",
      "Recall: 0.87\n",
      "Specificity: 0.95\n",
      "Precision: 0.94\n",
      "NPV: 0.88\n",
      "\n",
      "F1: 0.91\n",
      "MCC: 0.82\n",
      "AUC: 0.97\n",
      "\n"
     ]
    }
   ],
   "source": [
    "final_metric(training_hist, path=metric_path, mtype=\"train\")\n",
    "final_metric(training_hist, path=metric_path, mtype=\"valid\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "b6175bd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_figure(training_hist, fig_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22c396b9",
   "metadata": {},
   "source": [
    "# Evaluate on test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "9c177b70",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load data\n",
    "with open(\"./data/pkl/X_test.pkl\", \"rb\") as f:\n",
    "    X_test = pickle.load(f)\n",
    "with open(\"./data/pkl/y_test.pkl\", \"rb\") as f:\n",
    "    y_test = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "24377e91",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20892    A student filmmaker enlists a B-grade actress ...\n",
       "13280    This movie has a \"big production\" feel that I ...\n",
       "29002    A vampire's's henchman wants to call her after...\n",
       "6858     Don't get me wrong, I assumed this movie would...\n",
       "21664    Swedish action movies have over the past few y...\n",
       "                               ...                        \n",
       "12939    \"Three Daring Daughters\" is a sickly sweet, ro...\n",
       "20460    I too am a House Party Fan...House Party I is ...\n",
       "9273     I just came back from a pre-release viewing of...\n",
       "6213     This is a very intriguing short movie by David...\n",
       "29034    Yes, that's right, it is. I firmly believe tha...\n",
       "Name: review, Length: 5869, dtype: object"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "c8bfb0c5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20892    0\n",
       "13280    1\n",
       "29002    0\n",
       "6858     0\n",
       "21664    0\n",
       "        ..\n",
       "12939    0\n",
       "20460    0\n",
       "9273     1\n",
       "6213     1\n",
       "29034    1\n",
       "Name: sentiment, Length: 5869, dtype: int64"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "3435a919",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = \"bert-base-cased\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "3c3c1565",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cwd /home/lichang/projects/ai_cup-movie\n",
      "metric_path: /home/lichang/projects/ai_cup-movie/result/bert-base-cased_bs_8_epo4/test/metrics\n",
      "model_path: /home/lichang/projects/ai_cup-movie/result/bert-base-cased_bs_8_epo4/test/model\n",
      "history_path: /home/lichang/projects/ai_cup-movie/result/bert-base-cased_bs_8_epo4/test/history\n",
      "fig_path: /home/lichang/projects/ai_cup-movie/result/bert-base-cased_bs_8_epo4/test/figures\n"
     ]
    }
   ],
   "source": [
    "metric_path, _, history_path, fig_path = setting_path(\n",
    "    model_name, batch_size, epochs, mode=\"test\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "632aae22",
   "metadata": {},
   "outputs": [],
   "source": [
    "# tokenize\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name, do_lower_case=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "e801d555",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tokenizing for bert input\n"
     ]
    }
   ],
   "source": [
    "input_ids_te, attention_masks_te, labels_te = tokenizing_for_bert_eval(\n",
    "    X_test.values, y_test.values, tokenizer\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "8fecf87b",
   "metadata": {},
   "outputs": [],
   "source": [
    "testdataset = TensorDataset(input_ids_te, attention_masks_te, labels_te)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "5c51091e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5869"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(testdataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "e2ba297c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-cased were not used when initializing BertForSequenceClassification: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias']\n",
      "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-cased and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = AutoModelForSequenceClassification.from_pretrained(\n",
    "    model_name,\n",
    "    num_labels=2,\n",
    "    output_attentions=False,\n",
    "    output_hidden_states=False,\n",
    "    hidden_dropout_prob=0.4,\n",
    "    attention_probs_dropout_prob=0.25,\n",
    ")\n",
    "model.to(device)\n",
    "\n",
    "PATH = \"./result/bert-base-cased_bs_8_epo4/model/model.pkl\"\n",
    "model.load_state_dict(torch.load(PATH))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "ff399784",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test loss: 0.43\n",
      "test acc: 0.91\n",
      "-------------------------\n"
     ]
    }
   ],
   "source": [
    "training_hist = []\n",
    "\n",
    "N_test = len(testdataset)\n",
    "\n",
    "test_loader = DataLoader(testdataset, shuffle=False, batch_size=16)\n",
    "\n",
    "history = eval_data(\n",
    "    model=model,\n",
    "    test_loader=test_loader,\n",
    "    N_test=N_test,\n",
    "    device=device,\n",
    ")\n",
    "\n",
    "training_hist.append(history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "83289aa7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save trainin_history\n",
    "with open(os.path.join(history_path, \"hist.pkl\"), \"wb\") as f:\n",
    "    pickle.dump(training_hist, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "e58f19d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[test average]\n",
      "\n",
      "ACC: 0.91\n",
      "LOSS: 0.43\n",
      "\n",
      "Recall: 0.93\n",
      "Specificity: 0.9\n",
      "Precision: 0.9\n",
      "NPV: 0.92\n",
      "\n",
      "F1: 0.92\n",
      "MCC: 0.83\n",
      "AUC: 0.97\n",
      "\n"
     ]
    }
   ],
   "source": [
    "final_metric(training_hist, metric_path=metric_path, mtype=\"test\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a1f3722",
   "metadata": {},
   "source": [
    "# Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "94349d6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"./data/pkl/test_new.pkl\", \"rb\") as f:\n",
    "    test = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "56def13f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>review</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>22622</td>\n",
       "      <td>Robert Lansing plays a scientist experimenting...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10162</td>\n",
       "      <td>Well I've enjoy this movie, even though someti...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>17468</td>\n",
       "      <td>First things first - though I believe Joel Sch...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>42579</td>\n",
       "      <td>I watched this movie on the grounds that Amber...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>701</td>\n",
       "      <td>A certain sexiness underlines even the dullest...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29336</th>\n",
       "      <td>30370</td>\n",
       "      <td>It is difficult to rate a writer/director's fi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29337</th>\n",
       "      <td>18654</td>\n",
       "      <td>After watching this movie once, it quickly bec...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29338</th>\n",
       "      <td>47985</td>\n",
       "      <td>Even though i sat and watched the whole thing,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29339</th>\n",
       "      <td>9866</td>\n",
       "      <td>Warning Spoilers following. Superb recreation ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29340</th>\n",
       "      <td>35559</td>\n",
       "      <td>My, my, my: Peter Cushing and Donald Pleasance...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>29341 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          ID                                             review\n",
       "0      22622  Robert Lansing plays a scientist experimenting...\n",
       "1      10162  Well I've enjoy this movie, even though someti...\n",
       "2      17468  First things first - though I believe Joel Sch...\n",
       "3      42579  I watched this movie on the grounds that Amber...\n",
       "4        701  A certain sexiness underlines even the dullest...\n",
       "...      ...                                                ...\n",
       "29336  30370  It is difficult to rate a writer/director's fi...\n",
       "29337  18654  After watching this movie once, it quickly bec...\n",
       "29338  47985  Even though i sat and watched the whole thing,...\n",
       "29339   9866  Warning Spoilers following. Superb recreation ...\n",
       "29340  35559  My, my, my: Peter Cushing and Donald Pleasance...\n",
       "\n",
       "[29341 rows x 2 columns]"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "2c3ab606",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data = test[\"review\"].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "f52cdf45",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tokenizing for bert input\n"
     ]
    }
   ],
   "source": [
    "input_ids, attention_masks = tokenizing_for_bert_pred(test_data, tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "2ea11292",
   "metadata": {},
   "outputs": [],
   "source": [
    "testdataset = TensorDataset(input_ids, attention_masks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "f0a6e090",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "29341"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(testdataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "279888fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-cased were not used when initializing BertForSequenceClassification: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias']\n",
      "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-cased and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = AutoModelForSequenceClassification.from_pretrained(\n",
    "    model_name,\n",
    "    num_labels=2,\n",
    "    output_attentions=False,\n",
    "    output_hidden_states=False,\n",
    "    hidden_dropout_prob=0.4,\n",
    "    attention_probs_dropout_prob=0.25,\n",
    ")\n",
    "model.to(device)\n",
    "\n",
    "PATH = \"./result/bert-base-cased_bs_8_epo4/train/model/model.pkl\"\n",
    "model.load_state_dict(torch.load(PATH))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "ccc4df4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_loader = DataLoader(testdataset, shuffle=False, batch_size=16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "id": "4b92a302",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = []\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    for batch in test_loader:\n",
    "        b_input_ids = batch[0].to(device)\n",
    "        b_input_mask = batch[1].to(device)\n",
    "\n",
    "        output = model(b_input_ids, attention_mask=b_input_mask)\n",
    "        logits = output[0]\n",
    "\n",
    "        _, yhat = torch.max(logits.data, 1)\n",
    "\n",
    "        pred.extend(yhat.cpu().detach().numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "id": "4a09318b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "29341\n"
     ]
    }
   ],
   "source": [
    "print(len(pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "id": "1d3ebf09",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "29341"
      ]
     },
     "execution_count": 153,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "id": "a1a1fd49",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>22622</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10162</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>17468</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>42579</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>701</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29336</th>\n",
       "      <td>30370</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29337</th>\n",
       "      <td>18654</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29338</th>\n",
       "      <td>47985</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29339</th>\n",
       "      <td>9866</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29340</th>\n",
       "      <td>35559</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>29341 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          ID  sentiment\n",
       "0      22622          1\n",
       "1      10162          1\n",
       "2      17468          0\n",
       "3      42579          0\n",
       "4        701          0\n",
       "...      ...        ...\n",
       "29336  30370          0\n",
       "29337  18654          1\n",
       "29338  47985          0\n",
       "29339   9866          0\n",
       "29340  35559          0\n",
       "\n",
       "[29341 rows x 2 columns]"
      ]
     },
     "execution_count": 156,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "submission = pd.DataFrame({\"ID\": test[\"ID\"].values, \"sentiment\": pred})\n",
    "submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "id": "1137548b",
   "metadata": {},
   "outputs": [],
   "source": [
    "submission.to_csv(\"./submission.csv\", encoding=\"utf-8\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4dd18653",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.0 64-bit ('py38': virtualenvwrapper)",
   "language": "python",
   "name": "python380jvsc74a57bd0aad9fa7f6ed343a042bd460ce7fa15eb6fc8d0afdca2e8e62a1852ae0075cd4e"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
